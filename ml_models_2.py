# -*- coding: utf-8 -*-
"""ML_models_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KI2EronRYN1ODHdYfnBbRgAWCmxbiy1B
"""

from sklearn.neighbors import KNeighborsClassifier
from keras.datasets import mnist
import tensorflow
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.metrics import cohen_kappa_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_recall_curve, roc_curve, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from sklearn.metrics import confusion_matrix,classification_report,ConfusionMatrixDisplay
from sklearn.preprocessing import LabelEncoder
import sklearn.metrics as metrics


import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.metrics import cohen_kappa_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_recall_curve, roc_curve, confusion_matrix
from imblearn.metrics import specificity_score
from imblearn.metrics import sensitivity_score
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from sklearn import metrics
from tensorflow import keras


(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()

X_train = X_train.reshape(-1, 784)
X_test = X_test.reshape(-1, 784)

X_train = X_train.astype('float32') / 255.0
X_test = X_test.astype('float32') / 255.0
model = KNeighborsClassifier(n_neighbors=5)
model.fit(X_train, y_train)


y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='macro')
recall = recall_score(y_test, y_pred, average='macro')
f1 = f1_score(y_test, y_pred, average='macro')
kappa = cohen_kappa_score(y_test, y_pred)
specificity = specificity_score(y_test, y_pred, average='macro')
sensitive = sensitivity_score(y_test, y_pred, average='macro')
mae_lR = metrics.mean_absolute_error(y_test, y_pred)
mse_LR = metrics.mean_squared_error(y_test, y_pred)

print(f"Accuracy : {accuracy:.2f}")
print(f"Precision : {precision:.2f}")
print(f"Recall : {recall:.2f}")
print(f"F1 score : {f1:.2f}")
print('Cohens kappa: %f' % kappa)
print(f"Specificity : {specificity:.2f}")
print(f"Sensitivity : {sensitive:.2f}")
print(f"MAE : {mae_lR:.2f}")
print(f"MSE : {mse_LR:.2f}")

cm = confusion_matrix(y_test, y_pred)
cm_df = pd.DataFrame(cm, index=range(10), columns=range(10))

plt.figure(figsize=(8, 6))
sns.heatmap(cm_df, annot=True, fmt='d')
plt.title('Confusion Matrix')
plt.ylabel('Actual Values')
plt.xlabel('Predicted Values')
plt.show()

report = classification_report(y_test, y_pred)
print(f"Classification Report:\n{report}")

from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score
from sklearn.metrics import precision_recall_curve
from sklearn.preprocessing import label_binarize
from sklearn.metrics import roc_auc_score
pred_prob = model.predict_proba(X_test)
y_pred_lr= model.predict_proba(X_test)
random_probs = [0 for i in range(len(y_test))]
fpr = {}
tpr = {}
thresh ={}
n_class = 10
for i in range(n_class):
  fpr[i], tpr[i], thresh[i] = roc_curve(y_test, y_pred_lr[:,i], pos_label=i)

colors = ['orange', 'green', 'blue', 'red', 'purple', 'brown','yellow','black','pink','grey']
for i in range(n_class):
  plt.plot(fpr[i], tpr[i], linestyle='--', color=colors[i], label='Class {}'.format(i))
plt.title('ROC Curve')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend(loc='best')
plt.show()
plt.savefig('Multiclass ROC',dpi=300);



n_classes = 10
average_auc = 0.0
y_test_binarized = label_binarize(y_test, classes=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
for i in range(n_classes):
    average_auc += roc_auc_score(y_test_binarized[:, i], pred_prob[:, i])

average_auc /= n_classes

print("Average AUC:", average_auc)



precision = dict()
recall = dict()

for i in range(n_class):
    precision[i], recall[i], _ = precision_recall_curve(y_test_binarized[:, i], pred_prob[:, i])

def print_recalls_precision(recall, precision, title):
    plt.figure(figsize=(6, 6))
    for i in range(n_class):
        plt.plot(recall[i], precision[i], linestyle='--', color=colors[i], label='Class {}'.format(i))
    plt.xlabel("Recall", fontsize=16)
    plt.ylabel("Precision", fontsize=16)
    plt.title("Precision vs Recall plot - {0}".format(title), fontsize=16)
    plt.axis([0, 1, 0, 1])
    plt.legend(loc="best")
    plt.show()

print_recalls_precision(recall, precision, "KNN")

model6 = GradientBoostingClassifier(n_estimators=50, learning_rate=1.0, max_depth=3,random_state=42)
model6.fit(X_train, y_train)
y_pred = model6.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='macro')
recall = recall_score(y_test, y_pred, average='macro')
f1 = f1_score(y_test, y_pred, average='macro')
kappa = cohen_kappa_score(y_test, y_pred)
specificity = specificity_score(y_test, y_pred, average='macro')
sensitive = sensitivity_score(y_test, y_pred, average='macro')
mae_lR = metrics.mean_absolute_error(y_test, y_pred)
mse_LR = metrics.mean_squared_error(y_test, y_pred)

print(f"Accuracy Gradient Boosting: {accuracy:.2f}")
print(f"Precision Gradient Boosting: {precision:.2f}")
print(f"Recall Gradient Boosting: {recall:.2f}")
print(f"F1 score Gradient Boosting: {f1:.2f}")
print('Cohens kappa: %f' % kappa)
print(f"Specificity Gradient Boosting: {specificity:.2f}")
print(f"Sensitivity Gradient Boosting: {sensitive:.2f}")
print(f"MAE Gradient Boosting: {mae_lR:.2f}")
print(f"MSE Gradient Boosting: {mse_LR:.2f}")

cm = confusion_matrix(y_test, y_pred)
cm_df = pd.DataFrame(cm, index=range(10), columns=range(10))

plt.figure(figsize=(8, 6))
sns.heatmap(cm_df, annot=True, fmt='d')
plt.title('Confusion Matrix')
plt.ylabel('Actual Values')
plt.xlabel('Predicted Values')
plt.show()

y_pred = model6.predict(X_test)
report = classification_report(y_test, y_pred)
print(f"Classification Report:\n{report}")
from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score
from sklearn.metrics import precision_recall_curve
from sklearn.preprocessing import label_binarize
from sklearn.metrics import roc_auc_score
pred_prob = model6.predict_proba(X_test)
y_pred_lr= model6.predict_proba(X_test)
random_probs = [0 for i in range(len(y_test))]
fpr = {}
tpr = {}
thresh ={}
n_class = 10
for i in range(n_class):
  fpr[i], tpr[i], thresh[i] = roc_curve(y_test, y_pred_lr[:,i], pos_label=i)

colors = ['orange', 'green', 'blue', 'red', 'purple', 'brown','yellow','black','pink','grey']
for i in range(n_class):
  plt.plot(fpr[i], tpr[i], linestyle='--', color=colors[i], label='Class {}'.format(i))
plt.title('ROC Curve')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend(loc='best')
plt.show()
plt.savefig('Multiclass ROC',dpi=300);


y_test_binarized = label_binarize(y_test, classes=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
n_classes = 10
average_auc = 0.0

for i in range(n_classes):
    average_auc += roc_auc_score(y_test_binarized[:, i], pred_prob[:, i])

average_auc /= n_classes

print("Average AUC:", average_auc)


y_test_binarized = label_binarize(y_test, classes=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
precision = dict()
recall = dict()

for i in range(n_class):
    precision[i], recall[i], _ = precision_recall_curve(y_test_binarized[:, i], pred_prob[:, i])

def print_recalls_precision(recall, precision, title):
    plt.figure(figsize=(6, 6))
    for i in range(n_class):
        plt.plot(recall[i], precision[i], linestyle='--', color=colors[i], label='Class {}'.format(i))
    plt.xlabel("Recall", fontsize=16)
    plt.ylabel("Precision", fontsize=16)
    plt.title("Precision vs Recall plot - {0}".format(title), fontsize=16)
    plt.axis([0, 1, 0, 1])
    plt.legend(loc="best")
    plt.show()

print_recalls_precision(recall, precision, "Gradient Boosting")

from keras.datasets import mnist
import tensorflow
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.layers import Conv2D, MaxPooling2D
from tensorflow.keras.layers import BatchNormalization
from keras.utils import to_categorical
# Model configuration
batch_size = 250
no_epochs = 10
no_classes = 10
validation_split = 0.2
verbosity = 1
# Load MNIST dataset
(input_train, target_train), (input_test, target_test) =mnist.load_data()
# Shape of the input sets
input_train_shape = input_train.shape
input_test_shape = input_test.shape
# Keras layer input shape
input_shape = (input_train_shape[1], input_train_shape[2], 1)
# Reshape the training data to include channels
input_train = input_train.reshape(input_train_shape[0], input_train_shape[1],
input_train_shape[2], 1)
input_test = input_test.reshape(input_test_shape[0], input_test_shape[1], input_test_shape[2],
1)
# Parse numbers as floats
input_train = input_train.astype('float32')
input_test = input_test.astype('float32')
# Normalize input data
input_train = input_train / 255
input_test = input_test / 255
#Building a Model Without Batch Normalization
model = Sequential()
model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Flatten())
model.add(Dense(256, activation='relu'))

model.add(Dense(no_classes, activation='softmax'))

model.summary()
# Compile the model
model.compile(loss=tensorflow.keras.losses.sparse_categorical_crossentropy,
optimizer=tensorflow.keras.optimizers.Adam(),
metrics=['accuracy'])

# Fit data to model
history = model.fit(input_train, target_train,
batch_size=batch_size,
epochs=no_epochs,
verbose=verbosity,
validation_split=validation_split)

score = model.evaluate(input_test, target_test, verbose=0)
print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')

import matplotlib.pyplot as plt
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['train', 'test'], loc='lower right')
plt.title("Accuracy: Without Batch Normalization")
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss : Without Batch Normalization ')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()

from keras.utils.vis_utils import plot_model
plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)

y_pred = model.predict(input_test)
y_pred_classes = np.argmax(y_pred, axis=1)  # Convert predictions to class labels

accuracy = accuracy_score(target_test, y_pred_classes)
precision = precision_score(target_test, y_pred_classes, average='macro')
recall = recall_score(target_test, y_pred_classes, average='macro')
f1 = f1_score(target_test, y_pred_classes, average='macro')
kappa = cohen_kappa_score(target_test, y_pred_classes)

print(f"Accuracy: {accuracy:.2f}")
print(f"Precision: {precision:.2f}")
print(f"Recall: {recall:.2f}")
print(f"F1 score: {f1:.2f}")
print(f"Cohen's kappa: {kappa:.2f}")

cm = confusion_matrix(target_test, y_pred_classes)
cm_df = pd.DataFrame(cm, index=range(10), columns=range(10))

plt.figure(figsize=(8, 6))
sns.heatmap(cm_df, annot=True, fmt='d')
plt.title('Confusion Matrix')
plt.ylabel('Actual Values')
plt.xlabel('Predicted Values')
plt.show()