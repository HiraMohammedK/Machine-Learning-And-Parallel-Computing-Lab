# -*- coding: utf-8 -*-
"""Data-Preprocessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15eRCMbdDprE_ZHL42SIkfq4IL1pILcON
"""

!git clone https://github.com/iamavieira/handwritten-digits-mnist

import os
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical
import gzip
import shutil
import struct


# Define paths to the dataset
train_path = '/content/handwritten-digits-mnist/data/train'
test_path = '/content/handwritten-digits-mnist/data/test'

def list_files(path):
    for root, dirs, files in os.walk(path):
        level = root.replace(path, '').count(os.sep)
        indent = ' ' * 4 * (level)
        print(f'{indent}{os.path.basename(root)}/')
        subindent = ' ' * 4 * (level + 1)
        for f in files:
            print(f'{subindent}{f}')

# List files in the train and test directories
print("Contents of the train folder:")
list_files(train_path)

print("\nContents of the test folder:")
list_files(test_path)

def extract_gz_files(path):
    for root, dirs, files in os.walk(path):
        for file in files:
            if file.endswith('.gz'):
                file_path = os.path.join(root, file)
                with gzip.open(file_path, 'rb') as f_in:
                    with open(file_path[:-3], 'wb') as f_out:
                        shutil.copyfileobj(f_in, f_out)

# Extract gz files
extract_gz_files('/content/handwritten-digits-mnist')

def load_images(file_path):
    with open(file_path, 'rb') as f:
        _, num_images, rows, cols = struct.unpack('>IIII', f.read(16))
        images = np.fromfile(f, dtype=np.uint8).reshape(num_images, rows, cols)
    return images

def load_labels(file_path):
    with open(file_path, 'rb') as f:
        _, num_labels = struct.unpack('>II', f.read(8))
        labels = np.fromfile(f, dtype=np.uint8)
    return labels

# Load train and test data
train_images = load_images('/content/handwritten-digits-mnist/data/train/train-images-idx3-ubyte')
train_labels = load_labels('/content/handwritten-digits-mnist/data/train/train-labels-idx1-ubyte')
test_images = load_images('/content/handwritten-digits-mnist/data/test/test-images-idx3-ubyte')
test_labels = load_labels('/content/handwritten-digits-mnist/data/test/test-labels-idx1-ubyte')

# Normalize pixel values
train_images = train_images / 255.0
test_images = test_images / 255.0

# One-hot encode the labels
train_labels = to_categorical(train_labels, num_classes=10)
test_labels = to_categorical(test_labels, num_classes=10)

print('Performing one hot encoding...')
print('Train labels: ')
print(train_labels)
print('Test labels: ')
print(test_labels)

# Split the training data into training and validation sets
train_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels, test_size=0.2, random_state=42)

# Print shapes of the datasets
print(f'Train images shape: {train_images.shape}')
print(f'Validation images shape: {val_images.shape}')
print(f'Test images shape: {test_images.shape}')
print(f'Train labels shape: {train_labels.shape}')
print(f'Validation labels shape: {val_labels.shape}')
print(f'Test labels shape: {test_labels.shape}')

