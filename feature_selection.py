# -*- coding: utf-8 -*-
"""Feature-Selection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11LjDmabCUE2aQRQgb03ZyRHhQQcJ9e0v
"""

from sklearn.datasets import load_iris
import pandas as pd

# Load the Iris dataset
iris = load_iris()
X = iris.data
y = iris.target

# Convert to DataFrame for EDA
df = pd.DataFrame(X, columns=iris.feature_names)
df['target'] = y

df.head()

import seaborn as sns
import matplotlib.pyplot as plt

# Pairplot to visualize the relationships between features
sns.pairplot(df, hue='target', markers=['o', 's', 'D'])
plt.show()

# Correlation matrix
corr_matrix = df.corr()
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')
plt.show()

from sklearn.feature_selection import SelectKBest, f_classif

# Select top 2 features using univariate selection
k_best = SelectKBest(score_func=f_classif, k=2)
X_new = k_best.fit_transform(X, y)

# Get the selected feature indices
selected_indices = k_best.get_support(indices=True)
selected_features = [iris.feature_names[i] for i in selected_indices]
print(f'Selected features: {selected_features}')

from sklearn.ensemble import RandomForestClassifier
import numpy as np

# Fit a Random Forest model
rf = RandomForestClassifier(n_estimators=100)
rf.fit(X, y)

# Get feature importances
importances = rf.feature_importances_
indices = np.argsort(importances)[::-1]

# Print feature ranking
print("Feature ranking:")
for f in range(X.shape[1]):
    print(f"{f + 1}. feature {indices[f]} ({importances[indices[f]]})")

# Select top 2 features based on importance
selected_indices_rf = indices[:2]
selected_features_rf = [iris.feature_names[i] for i in selected_indices_rf]
print(f'Selected features: {selected_features_rf}')

from sklearn.svm import SVC
from sklearn.feature_selection import RFE

# Fit an SVM model
svc = SVC(kernel='linear')

# Perform RFE
rfe = RFE(estimator=svc, n_features_to_select=2)
rfe.fit(X, y)

# Get selected feature indices
selected_indices_rfe = rfe.get_support(indices=True)
selected_features_rfe = [iris.feature_names[i] for i in selected_indices_rfe]
print(f'Selected features: {selected_features_rfe}')

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Logistic Regression model
lr = LogisticRegression(max_iter=200)

# Evaluate on original features
lr.fit(X_train, y_train)
y_pred = lr.predict(X_test)
print("Performance on original features:")
print(f'Accuracy: {accuracy_score(y_test, y_pred)}')
print(classification_report(y_test, y_pred))

# Evaluate on selected features by Univariate Selection
X_train_kbest = X_train[:, selected_indices]
X_test_kbest = X_test[:, selected_indices]
lr.fit(X_train_kbest, y_train)
y_pred_kbest = lr.predict(X_test_kbest)
print("Performance on selected features (Univariate Selection):")
print(f'Accuracy: {accuracy_score(y_test, y_pred_kbest)}')
print(classification_report(y_test, y_pred_kbest))

# Evaluate on selected features by Random Forest
X_train_rf = X_train[:, selected_indices_rf]
X_test_rf = X_test[:, selected_indices_rf]
lr.fit(X_train_rf, y_train)
y_pred_rf = lr.predict(X_test_rf)
print("Performance on selected features (Random Forest):")
print(f'Accuracy: {accuracy_score(y_test, y_pred_rf)}')
print(classification_report(y_test, y_pred_rf))

# Evaluate on selected features by RFE
X_train_rfe = X_train[:, selected_indices_rfe]
X_test_rfe = X_test[:, selected_indices_rfe]
lr.fit(X_train_rfe, y_train)
y_pred_rfe = lr.predict(X_test_rfe)
print("Performance on selected features (RFE):")
print(f'Accuracy: {accuracy_score(y_test, y_pred_rfe)}')
print(classification_report(y_test, y_pred_rfe))